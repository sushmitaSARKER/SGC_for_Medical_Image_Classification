{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import time, os\n",
    "\n",
    "from models.dataset_classification_vindr_supervised import MakeDataset_VinDr_classification\n",
    "from models.unet_score_model_conditional import UNetScoreModel_conditional\n",
    "from models.likelihood_computation import ode_likelihood\n",
    "from models.utils import get_lr\n",
    "from models.vpsde import VPSDE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuda setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Available GPUs:  2\n",
      "NVIDIA A30\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "NVIDIA A30\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "## Devices\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(\"Available GPUs: \", torch.cuda.device_count())\n",
    "# print(\"Current device ID: \", torch.cuda.current_device())\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "\n",
    "try: \n",
    "    if device.type == 'cuda':\n",
    "        print(torch.cuda.get_device_name(0))\n",
    "        print('Memory Usage:')\n",
    "        print('Allocated:', round(torch.cuda.memory_allocated(1)/1024**3,1), 'GB')\n",
    "        print('Cached:   ', round(torch.cuda.memory_reserved(1)/1024**3,1), 'GB')\n",
    "except: \n",
    "    print(\"No second GPU Found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_tolerance = 1e-7\n",
    "\n",
    "n_epochs = 1\n",
    "batch_size = 32\n",
    "lr = 1e-4 \n",
    "beta_min=0.1\n",
    "beta_max=20\n",
    "target_size = 384\n",
    "channels= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= \"VinDr\"\n",
    "sde_type= \"VPSDE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"../ST_Mammo/dataset/VinDr_Mammo/Images_Processed_CLAHE\"\n",
    "label_dir_csv = \"../ST_Mammo/dataset/VinDr_Mammo/breast-level_annotations.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total benign and malignant images in train: 15209 790\n",
      "Total benign and malignant images in test: 3802 198\n",
      "Train and Test files: 15999, 4000. Current mode: train\n",
      "Total benign and malignant images in train: 15209 790\n",
      "Total benign and malignant images in test: 3802 198\n",
      "Train and Test files: 15999, 4000. Current mode: test\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.Resize((target_size, target_size)), \n",
    "                                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                transforms.RandomVerticalFlip(p=0.5),\n",
    "                                transforms.ToTensor()])\n",
    "transform_test = transforms.Compose([transforms.Resize((target_size, target_size)),\n",
    "                                transforms.ToTensor()])\n",
    "\n",
    "train_dataloader = MakeDataset_VinDr_classification(image_dir = image_dir,\n",
    "                                                        label_dir_csv = label_dir_csv,\n",
    "                                                        transform=transform,\n",
    "                                                        mode='train',\n",
    "                                                        target_size= target_size)\n",
    "\n",
    "test_dataloader = MakeDataset_VinDr_classification(image_dir = image_dir,\n",
    "                                                        label_dir_csv = label_dir_csv,\n",
    "                                                        transform=transform_test,\n",
    "                                                        mode='test',\n",
    "                                                        target_size= target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders for training and testing\n",
    "\n",
    "train_loader = DataLoader(train_dataloader, batch_size=batch_size, shuffle=True, num_workers=64)\n",
    "test_loader = DataLoader(test_dataloader, batch_size=batch_size, num_workers=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sde_model = VPSDE(\n",
    "    beta_min=beta_min,\n",
    "    beta_max=beta_max)\n",
    "\n",
    "score_model = torch.nn.DataParallel(UNetScoreModel_conditional(\n",
    "                        marginal_prob_std= sde_model.marginal_prob,\n",
    "                        sde= sde_type,\n",
    "                        n_classes= 2,\n",
    "                    )).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model, \n",
    "            sde_model, \n",
    "            x, \n",
    "            y,\n",
    "            eps=1e-5, \n",
    "            mode='train'):\n",
    "    \"\"\"The loss function for training score-based generative models.\n",
    "\n",
    "    Args:\n",
    "    model: A PyTorch model instance that represents a \n",
    "        time-dependent score-based model.\n",
    "    x: A mini-batch of training data.    \n",
    "    marginal_prob_std: A function that gives the standard deviation of \n",
    "        the perturbation kernel.\n",
    "    eps: A tolerance value for numerical stability.\n",
    "    \"\"\"\n",
    "    random_t = torch.rand(x.shape[0], device=x.device) * (1. - eps) + eps  \n",
    "    z = torch.randn_like(x)\n",
    "    mean, std = sde_model.marginal_prob(x, random_t)\n",
    "    perturbed_x = (mean + std[:, None, None, None] * z).to(device)\n",
    "    score = model(perturbed_x, random_t, y)\n",
    "    if mode == 'test':\n",
    "        loss_score = torch.sum((score * std[:, None, None, None] + z)**2, dim=(1,2,3))\n",
    "    else:\n",
    "        loss_score = torch.mean(torch.sum((score * std[:, None, None, None] + z)**2, dim=(1,2,3)))\n",
    "    return loss_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(score_model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.2)\n",
    "folder_name = \"saved_checkpoints\"\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Epoch:  1  and current learning rate:  0.0001 ####\n",
      "training complete for items:  15999\n",
      "Average Loss:  107719.90288382281\n",
      "Time taken:  143.41941714286804\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    epoch_time = time.time()\n",
    "    curr_lr = get_lr(optimizer)\n",
    "    print(\"#### Epoch: \", epoch, \" and current learning rate: \", curr_lr, \"####\")\n",
    "    avg_loss = 0.\n",
    "    num_items = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        x, y = data\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        loss = loss_fn(\n",
    "            model= score_model,\n",
    "            sde_model= sde_model,\n",
    "            x= x, \n",
    "            y= y,\n",
    "            mode= 'train'\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()    \n",
    "        optimizer.step()\n",
    "        avg_loss += loss.item() * x.shape[0]\n",
    "        num_items += x.shape[0]\n",
    "        if (num_items + 1) % 100 == 0:\n",
    "            print(\"training complete for items: \", num_items)\n",
    "    print(\"Average Loss: \", avg_loss / num_items)\n",
    "    print(\"Time taken: \", time.time() - epoch_time)\n",
    "    if epoch % 20 == 0:\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
